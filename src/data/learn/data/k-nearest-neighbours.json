{
  "title": "K-Nearest Neighbors",
  "slug": "k-nearest-neighbors",
  "description": "Learn the fundamentals of K-Nearest Neighbors (KNN) with step-by-step tutorials, video guides, and practical applications.",
  "category": "Tutorial",
  "date": "2024-5-2",
  "featured": false,
  "overview": {
    "definition": "K-Nearest Neighbors (KNN) is a simple, instance-based supervised learning algorithm used for classification and regression. It predicts the output for a new data point based on the majority label or average of its k closest neighbors.",
    "types": [
      "Classification: Assigns the class most common among k nearest neighbors.",
      "Regression: Predicts the average value of k nearest neighbors."
    ],
    "key_concepts": [
      "Distance Metrics: Euclidean, Manhattan, or Minkowski distance to find nearest neighbors.",
      "Choosing k: Number of neighbors impacts bias-variance tradeoff.",
      "Weighted Voting: Closer neighbors can have higher influence on prediction.",
      "Curse of Dimensionality: Performance can degrade in high-dimensional spaces.",
      "Lazy Learning: KNN does not train a model explicitly; computations occur at prediction time."
    ]
  },

  "tutorials": [
    {
      "title": "Implement k-Nearest Neighbors From Scratch",
      "url": "https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/",
      "description": "Step-by-step Python code to build KNN: distance functions, neighbor selection and prediction on Iris dataset."
    },
    {
      "title": "k-Nearest Neighbors (kNN) in Python",
      "url": "https://realpython.com/knn-python/",
      "description": "Hands-on guide using NumPy and scikit-learn: load data, fit KNeighborsClassifier and tune k."
    },
    {
      "title": "KNN Classification with scikit-learn",
      "url": "https://www.datacamp.com/tutorial/k-nearest-neighbor-classification-scikit-learn",
      "description": "Beginner-friendly walk-through: train/test split, model training, prediction, and confusion matrix."
    }
  ],

  "videos": [
    {
      "title": "KNN Explained Step by Step (with Python Code)",
      "url": "https://www.youtube.com/embed/j5trkIElkX8",
      "description": "Live coding using scikit-learn: load Iris data, fit KNN classifier, make and evaluate predictions."
    },
    {
      "title": "KNN Algorithm Explained (Python Walkthrough)",
      "url": "https://www.youtube.com/embed/Go8Jj_uqFGA",
      "description": "Step-by-step implementation: calculate Euclidean distances, choose k, fit neighbors and compute accuracy."
    },
    {
      "title": "KNN Classification in Python with scikit-learn",
      "url": "https://www.youtube.com/embed/UqYde-LULfs",
      "description": "Hands-on guide: split data, train KNeighborsClassifier, predict labels and visualize results."
    }
  ],

  "applications": [
    "Classification tasks like handwriting recognition (MNIST) or flower species identification (Iris).",
    "Regression tasks like predicting house prices using nearby examples.",
    "Recommendation systems based on similarity of user preferences.",
    "Anomaly detection by identifying points far from normal clusters."
  ],

  "resources": [
    {
      "title": "Scikit-learn KNN Documentation",
      "url": "https://scikit-learn.org/stable/modules/neighbors.html"
    },
    {
      "title": "KNN Algorithm Guide â€“ Towards Data Science",
      "url": "https://towardsdatascience.com/k-nearest-neighbors-3b534bb11d26"
    },
    {
      "title": "Comprehensive KNN Tutorial",
      "url": "https://www.geeksforgeeks.org/k-nearest-neighbors-knn-algorithm-for-machine-learning/"
    }
  ],

  "tips": [
    "Normalize or standardize features before applying KNN, as distance metrics are sensitive to scale.",
    "Experiment with different k values and distance metrics for optimal performance.",
    "Use weighted voting to give closer neighbors more influence in classification.",
    "KNN can be slow with large datasets; consider approximate nearest neighbors for efficiency."
  ]
}
